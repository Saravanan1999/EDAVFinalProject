[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDAV Project",
    "section": "",
    "text": "1 Introduction\nThis project aims to analyze the performance of stocks in each sector for major corporations by identifying trends and understanding the factors influencing stock price variations across various sectors. Stock prices are determined not only by a company’s performance but also by broader market trends, sector-specific dynamics, and external economic factors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "EDAV Project",
    "section": "1.1 Background",
    "text": "1.1 Background\nFor example, greater stock prices are frequently connected with technology companies because investors anticipate innovation and development from these companies. On the other hand, utility firms tend to have lower stock values due to the nature of their business, primarily dependent on consistent demand and regulated pricing. Understanding these distinctions is critical for investors looking to make educated decisions based on sectoral performance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "EDAV Project",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nThrough this analysis, we aim to explore:\n\nWhy some firms in the same industry outperform others.\nThe impact of factors such as market sentiment, growth prospects, competitive advantages, and financial soundness on stock performance.\nThe influence of external events such as economic downturns, market booms, and geopolitical crises on stock performance across sectors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "EDAV Project",
    "section": "1.3 Methodology",
    "text": "1.3 Methodology\nTo achieve these goals, we will:\n\nUtilize bar charts, scatter plots, and sector performance comparisons to visually highlight key insights.\nAnalyze the relative success of each sector over time.\nInvestigate the underlying causes of performance disparities using data-driven approaches.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#expected-outcomes",
    "href": "index.html#expected-outcomes",
    "title": "EDAV Project",
    "section": "1.4 Expected Outcomes",
    "text": "1.4 Expected Outcomes\nBy the end of the research, we aim to present:\n\nA clear, data-driven narrative about how different sectors perform in the market.\nInsights into the variables influencing their success.\n\nThese visual tools and analyses will enable us to better understand sectoral performance and provide actionable insights for informed investment decisions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nFor this project, we will use historical stock data for companies in three key sectors: Technology, Finance, and Healthcare. The dataset will span five years, allowing for a robust analysis of trends over time.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Sectors and Companies\n\n2.1.1.1 Technology:\n\nApple Inc. (AAPL)\nAlphabet Inc. Class C (GOOG)\nMeta Platforms Inc. Class A (META)\nMicrosoft Corp. (MSFT)\nNVIDIA Corporation (NVDA)\n\n\n\n2.1.1.2 Finance:\n\nBank of America (BAC)\nGoldman Sachs Group Inc. (GS)\nJPMorgan Chase & Co. (JPM)\nMorgan Stanley (MS)\nWells Fargo & Co. (WFC)\n\n\n\n2.1.1.3 Healthcare:\n\nAstraZeneca (AZN)\nJohnson & Johnson (JNJ)\nEli Lilly and Co. (LLY)\nMerck & Co., Inc. (MRK)\nPfizer Inc. (PFE)\n\n\n\n\n2.1.2 Data Source\nNasdaq collects data through its exchange from transactions conducted by various market participants, including institutional investors, brokers, market makers, and retail traders. The data encompasses details on market activity such as trades, order books, bid/ask prices, volumes, and timestamped events.\n\n2.1.2.1 Transaction Data\nEach trade, quote, and order is logged, providing insights into the dynamics of stock movements, liquidity, and market trends.\n\n\n2.1.2.2 Participants\nMarket participants, including broker-dealers and investors, generate real-time and historical data through their buying and selling activities.\n\n\n\n2.1.3 Format and Frequency\nThe data will be accessed in formats like CSV, JSON, or XML, which are compatible with analysis tools such as Python or R. The frequency of updates varies:\n\nDaily Data: Updated at the end of each trading day.\nIntraday (Minute-Level) Data: Real-time updates available during market hours.\n\n\n\n2.1.4 Key Data Dimensions\n\nDate: Trading date.\n\nOpen: Opening stock price.\n\nHigh: Highest price during the trading day.\n\nLow: Lowest price during the trading day.\n\nClose/Last: Closing price or last trade price.\n\nVolume: Total shares traded.\n\n\n\n2.1.5 Potential Issues\n\nData Gaps: Missing data during market holidays or after-hours trading.\nAdjustments: Stock splits and dividends may require corrections for consistency.\n\nData Volume: Handling minute-level data over five years for multiple companies may require significant processing power and storage.\n\n\n\n2.1.6 Data Import Plan\nThe data import strategy entails retrieving structured information from an API endpoint using HTTP requests that include appropriate headers to ensure successful communication. The JSON answer is processed and turned into a structured DataFrame, allowing for rapid data manipulation and analysis. Relevant data is then extracted and saved locally in a CSV file for further processing and analysis. This methodical methodology guarantees the smooth integration of raw data from an external source into a useful tabular format.\n\n\n2.1.7 Sources\nNasdaq’s market data services will be the primary source, with potential supplementary data from financial APIs or publicly available CSV datasets.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(readr)\n\n\nData fetching:\n\n\nCode\nfetch_and_save_data &lt;- function(api_url, csv_path) {\n  response &lt;- GET(api_url, add_headers(\"User-Agent\" = \"Mozilla/5.0\"))\n  \n  if (status_code(response) == 200) {\n    json_content &lt;- content(response, as = \"text\", encoding = \"UTF-8\")\n    parsed_data &lt;- fromJSON(json_content, flatten = TRUE)\n    \n    historical_data &lt;- parsed_data$data$tradesTable$rows\n    \n    data_frame &lt;- as.data.frame(historical_data)\n    \n    write_csv(data_frame, csv_path)\n    \n    print(paste(\"Data successfully saved to\", csv_path))\n  } else {\n    print(paste(\"Failed to fetch data. HTTP Status Code:\", status_code(response)))\n  }\n}\n\n\n###Finance Sector\nFetching data\n\n\nCode\n# bank\n#BAC_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/BAC/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=27\"\nBAC_csv_path &lt;- \"./Datasets/Banking/BAC Historical Data.csv\"\n#fetch_and_save_data(BAC_history_data_url, BAC_csv_path)\n\n# GS_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/GS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=26\"\nGS_csv_path &lt;- \"./Datasets/Banking/GS Historical Data.csv\"\n# fetch_and_save_data(GS_history_data_url, GS_csv_path)\n\n# JPM_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/JPM/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=29\"\nJPM_csv_path &lt;- \"./Datasets/Banking/JPM Historical Data.csv\"\n# fetch_and_save_data(JPM_history_data_url, JPM_csv_path)\n\n\n# MS_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=15\"\nMS_csv_path &lt;- \"./Datasets/Banking/MS Historical Data.csv\"\n# fetch_and_save_data(MS_history_data_url, MS_csv_path)\n\n\n# WFC_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=15\"\nWFC_csv_path &lt;- \"./Datasets/Banking/MS Historical Data.csv\"\n# fetch_and_save_data(WFC_history_data_url, WFC_csv_path)\n\n\nReading data:\n\n\nCode\nBAC &lt;- read_csv(BAC_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nGS &lt;- read_csv(GS_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nJPM &lt;- read_csv(JPM_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nMS &lt;- read_csv(MS_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nWFC &lt;- read_csv(WFC_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking Null Values:\n\n\nCode\nmissing_values &lt;- list(\n  \"BAC\" = colSums(is.na(BAC)),\n  \"GS\" = colSums(is.na(GS)),\n  \"JPM\" = colSums(is.na(JPM)),\n  \"MS\" = colSums(is.na(MS)),\n  \"WFC\" = colSums(is.na(WFC))\n)\n\nfor (name in names(missing_values)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(missing_values[[name]])\n  cat(\"\\n\")\n}\n\n\nMissing values in BAC dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in GS dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in JPM dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MS dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in WFC dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nVisualizing Missing Data:\n\n\nCode\nlibrary(ggplot2)\nlibrary(naniar)\n\n\nWarning: package 'naniar' was built under R version 4.4.2\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\n\n\n\n\nCode\n# List of datasets\ndata_list &lt;- list(BAC = BAC, GS = GS, JPM = JPM, MS = MS, WFC = WFC)\n\n# Generate missing value visualizations\nfor (name in names(data_list)) {\n  cat(\"Visualizing missing data for\", name, \"\\n\")\n  \n  # Plot\n  print(\n    vis_miss(data_list[[name]]) +\n      ggtitle(paste(\"Missing Data Visualization for\", name))\n  )\n}\n\n\nVisualizing missing data for BAC \n\n\n\n\n\n\n\n\n\nVisualizing missing data for GS \n\n\n\n\n\n\n\n\n\nVisualizing missing data for JPM \n\n\n\n\n\n\n\n\n\nVisualizing missing data for MS \n\n\n\n\n\n\n\n\n\nVisualizing missing data for WFC \n\n\n\n\n\n\n\n\n\n\n\nCode\n# List of datasets\ndata_list &lt;- list(BAC = BAC, GS = GS, JPM = JPM, MS = MS, WFC = WFC)\n\n# Combine all datasets into one data frame with a 'Dataset' column indicating the dataset name\ncombined_data &lt;- bind_rows(lapply(names(data_list), function(dataset_name) {\n  data &lt;- data_list[[dataset_name]]\n  data$Dataset &lt;- dataset_name\n  return(data)\n}))\n\n# Convert all columns to character type\ncombined_data &lt;- combined_data |&gt;\n  mutate(across(everything(), as.character))\n\n# Pivot longer and add a column for missing data\ncombined_data_long &lt;- combined_data |&gt;\n  pivot_longer(cols = -Dataset, names_to = \"Column\", values_to = \"Value\") |&gt;\n  mutate(Missing = is.na(Value))\n\n# Plot the missing data across datasets\nggplot(combined_data_long, aes(x = Column, y = Dataset, fill = Missing)) +\n  geom_tile(color = \"white\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"gray90\")) +\n  theme_minimal() +\n  ggtitle(\"Missing Data Visualization Across Datasets\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability\n\n\n\n\n\n\n\n\n\nFor the finance sector dataset, we have plotted two types of graphs:\nA missing value heatmap for each company, which shows that there are no missing values across any column for each company. A comparative heatmap of the five companies in the finance sector, which confirms that none of the columns in any of the five datasets have missing values.\n###Tech Sector\nFetching data\n\n\nCode\n#AAPL_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/AAPL/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=21\"\nAAPL_csv_path &lt;- \"./Datasets/TECH/AAPL Historical data.csv\"\n#fetch_and_save_data(AAPL_history_data_url, AAPL_csv_path)\n\n\n#GOOG_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/GOOG/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=32\"\nGOOG_csv_path &lt;- \"./Datasets/TECH/GOOG class C Historical data.csv\"\n#fetch_and_save_data(GOOG_history_data_url, GOOG_csv_path)\n\n# META_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/META/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=13\"\nMETA_csv_path &lt;- \"./Datasets/TECH/GOOG class C Historical data.csv\"\n# fetch_and_save_data(GOOG_history_data_url, GOOG_csv_path)\n \n\n# MSFT_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/META/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=13\"\nMSFT_csv_path &lt;- \"./Datasets/TECH/MSFT Historical data.csv\"\n# fetch_and_save_data(MSFT_history_data_url, MSFT_csv_path)\n\n# NVDA_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/NVDA/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=49\"\nNVDA_csv_path &lt;- \"./Datasets/TECH/NVDA historical data.csv\"\n# fetch_and_save_data(NVDA_history_data_url, NVDA_csv_path)\n\n\nReading data\n\n\nCode\naapl = read_csv(AAPL_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ngoog = read_csv(GOOG_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmeta = read_csv(META_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmsft = read_csv(MSFT_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nnvda = read_csv(NVDA_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n#missing data\ndatasets &lt;- list(\n  \"AAPL\" = aapl,\n  \"GOOG\" = goog,\n  \"META\" = meta,\n  \"MSFT\" = msft,\n  \"NVDA\" = nvda\n)\n\nfor (name in names(datasets)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(colSums(is.na(datasets[[name]])))\n  cat(\"\\n\")\n}\n\n\nMissing values in AAPL dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in GOOG dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in META dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MSFT dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in NVDA dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nCode\n#missing values visualisation\n#install.packages('naniar')\n#install.packages('VIM')\n#library(dplyr)\n#library(tidyverse)\n#library(ggplot2)\n#library(naniar)\n\n# Assuming the files are named file1, file2, ..., file5\naapl$Source &lt;- \"Apple\"\ngoog$Source &lt;- \"Google\"\nmeta$Source &lt;- \"Meta\"\nmsft$Source &lt;- \"Microsoft\"\nnvda$Source &lt;- \"Nvidia\"\n\n# Combine the datasets\nall_files &lt;- bind_rows(aapl, goog, meta, msft, nvda)\n\n# Reshape data for visualization\n# Create a missingness indicator for each column\nall_files &lt;- all_files  |&gt; \n  mutate(across(-Source, as.character))\n\n# Pivot the data\nmissing_long &lt;- all_files  |&gt; \n  pivot_longer(cols = -Source, names_to = \"Variable\", values_to = \"Value\")  |&gt; \n  mutate(Missing = is.na(Value))\nlibrary(ggplot2)\n\nggplot(missing_long, aes(x = Variable, y = Source, fill = Missing)) +\n  geom_tile(color = \"white\") +\n  scale_fill_manual(\n    values = c(\"TRUE\" = \"red\", \"FALSE\" = \"blue\"),\n    labels = c(\"TRUE\" = \"Missing\", \"FALSE\" = \"Not Missing\")\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Missing Data Across Files\",\n    x = \"Variables\",\n    y = \"Files\",\n    fill = \"Missing?\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThere are 2 of types visualizations we have done to depict the missing values in the data.One using regular ggplot and the other using the naniar package.As seen from the graphs, there are no missing values.This trend can be attributed to the fact that all stocks have a price and they are updated accordingly. To deal with historical data, NASDAQ would probably use multiple techniques like archival techniques and curation processes etc. Another widely known fact is that financial data is almost always very clean.\n###Healthcare and Pharma Sector\nFetch Data:\n\n\nCode\n# JNJ_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/JNJ/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=45\"\nJNJ_csv_path &lt;- \"./Datasets/Healthcare and Pharma/JNJ Historical data.csv\"\n# fetch_and_save_data(JNJ_history_data_url, JNJ_csv_path)\n# \n# \n# AZN_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/AZN/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=20\"\nAZN_csv_path &lt;- \"./Datasets/Healthcare and Pharma/AZN Historical data.csv\"\n# fetch_and_save_data(AZN_history_data_url, AZN_csv_path)\n# \n# \n# LLY_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/LLY/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=22\"\nLLY_csv_path &lt;- \"./Datasets/Healthcare and Pharma/LLY Historical data.csv\"\n# fetch_and_save_data(LLY_history_data_url, LLY_csv_path)\n# \n# MRK_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MRK/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=33\"\nMRK_csv_path &lt;- \"./Datasets/Healthcare and Pharma/MRK Historical data.csv\"\n# fetch_and_save_data(MRK_history_data_url, MRK_csv_path)\n# \n# PFE_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/PFE/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=49\"\nPFE_csv_path &lt;- \"./Datasets/Healthcare and Pharma/PFE Historical data.csv\"\n# fetch_and_save_data(PFE_history_data_url, PFE_csv_path)\n\n\nReading Data:\n\n\nCode\n# Reading the datasets using relative paths\njnj = read_csv(JNJ_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nazn = read_csv(AZN_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nlly = read_csv(LLY_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmrk = read_csv(MRK_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\npfe = read_csv(PFE_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\npharma_datasets &lt;- list(\n  \"JNJ\" = jnj,\n  \"AZN\" = azn,\n  \"LLY\" = lly,\n  \"MRK\" = mrk,\n  \"PFE\" = pfe\n)\n\nfor (name in names(pharma_datasets)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(colSums(is.na(pharma_datasets[[name]])))\n  cat(\"\\n\")\n}\n\n\nMissing values in JNJ dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in AZN dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in LLY dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MRK dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in PFE dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nMissing Values Visualisation\n\n\nCode\n# Assuming the files are named file1, file2, ..., file5\njnj$Source &lt;- \"JNJ\"\nazn$Source &lt;- \"AstraZeneca\"\nlly$Source &lt;- \"Eli Lilly\"\nmrk$Source &lt;- \"Merck&Co\"\npfe$Source &lt;- \"Pfizer\"\n\n# Combine the datasets\nall_files_health &lt;- bind_rows(jnj, azn, lly, mrk, pfe)\n\n# Reshape data for visualization\n# Create a missingness indicator for each column\nall_files_health &lt;- all_files_health  |&gt; \n  mutate(across(-Source, as.character))\n\n# Pivot the data\nmissing_long &lt;- all_files_health  |&gt; \n  pivot_longer(cols = -Source, names_to = \"Variable\", values_to = \"Value\")  |&gt; \n  mutate(Missing = is.na(Value))\nlibrary(ggplot2)\nlibrary(naniar)\n\ngg_miss_var(all_files_health, facet = Source) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Missing Data Visualization by File\")\n\n\n\n\n\n\n\n\n\nWe have used naniar package to visualise missing data. The x-axis shows the proportion of data missing in the dataset and here since its 0, it means there are no missing values. The reason why has been explained above.\nThere are 3 of types visualizations we have done to depict the missing values in the data. Two using regular ggplot and the other using the naniar package. As seen from the graphs, there are no missing values.This trend can be attributed to the fact that all stocks have a price and they are updated accordingly. To deal with historical data, NASDAQ would probably use multiple techniques like archival techniques and curation processes etc. Another widely known fact is that financial data is almost always very clean.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "4 Results",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#executive-summary",
    "href": "results.html#executive-summary",
    "title": "3  Results",
    "section": "4.1 Executive Summary",
    "text": "4.1 Executive Summary\nThis section presents the key findings from our sector-based financial analysis of Technology, Healthcare, and Banking stocks listed on NASDAQ over the past five years. Our analysis reveals distinct performance patterns, risk profiles, and sensitivities to economic indicators across the sectors. Notably, the Technology sector demonstrated robust growth and resilience, while the Banking sector exhibited higher volatility influenced by interest rate fluctuations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#stock-performances-on-each-sector",
    "href": "results.html#stock-performances-on-each-sector",
    "title": "3  Results",
    "section": "4.2 1. Stock Performances on each sector",
    "text": "4.2 1. Stock Performances on each sector\n\n4.2.1 1.1 Closing Price\n\n\nCode\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(readr)\nlibrary(tidyr)\nlibrary(lubridate)\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\nCode\nlibrary(zoo)  # for rollmean\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nCode\n# List the CSV files for each sector\nbanking_files &lt;- list.files(path = \"./Datasets/Banking/\", pattern = \"*.csv\", full.names = TRUE)\nbanking_files &lt;- banking_files[!grepl(\"_modified\", banking_files)]\n\ntech_files &lt;- list.files(path = \"./Datasets/TECH/\", pattern = \"*.csv\", full.names = TRUE)\ntech_files &lt;- tech_files[!grepl(\"_modified\", tech_files)]\n\nhealth_files &lt;- list.files(path = \"./Datasets/Healthcare and Pharma/\", pattern = \"*.csv\", full.names = TRUE)\nhealth_files &lt;- health_files[!grepl(\"_modified\", health_files)]\n\nsave_to_csv &lt;- function(data, file_path) {\n  write_csv(data, file_path)\n}\nstock_file_mapping &lt;- list()\n\n# Define the function to read and process data for a single file and sector\nread_sector_data &lt;- function(file_path, sector) {\n  data &lt;- read_csv(file_path, show_col_types = FALSE)  \n  \n  colnames(data) &lt;- tolower(gsub(\"\\\\s+\", \"_\", colnames(data)))  \n  \n  required_columns &lt;- c(\"date\", \"close\", \"open\", \"high\", \"low\")\n  missing_columns &lt;- setdiff(required_columns, colnames(data))\n  if (length(missing_columns) &gt; 0) {\n    stop(paste(\"Missing required columns in file:\", file_path, \n               \"-&gt; Missing columns:\", paste(missing_columns, collapse = \", \")))\n  }\n  \n  data &lt;- data |&gt;\n    mutate(\n      date = mdy(date),  \n      close = as.numeric(gsub(\"\\\\$\", \"\", close)),  \n      open = as.numeric(gsub(\"\\\\$\", \"\", open)),\n      high = as.numeric(gsub(\"\\\\$\", \"\", high)),\n      low = as.numeric(gsub(\"\\\\$\", \"\", low)),\n      volume = as.numeric(gsub(\",\", \"\", volume))  \n    ) |&gt;\n    mutate(\n      Sector = sector,\n      Source = tools::file_path_sans_ext(basename(file_path))\n    )\n  \n  stock_file_mapping[[unique(data$Source)]] &lt;&lt;- file_path\n  \n  return(data)\n}\n\n# Read and combine data for each sector\nbanking_data &lt;- bind_rows(lapply(banking_files, read_sector_data, sector = \"Banking\"))\ntech_data &lt;- bind_rows(lapply(tech_files, read_sector_data, sector = \"Technology\"))\nhealth_data &lt;- bind_rows(lapply(health_files, read_sector_data, sector = \"Healthcare\"))\n\n# Combine all sector data into one dataset\ncombined_data &lt;- bind_rows(banking_data, tech_data, health_data)\n\n# Rename 'Source' to 'Stock' before further processing\ncombined_data &lt;- combined_data |&gt;\n  rename(Stock = Source)\n\n# Create the faceted line chart with sectors arranged in rows\np &lt;- ggplot(combined_data, aes(x = date, y = close, color = Stock)) +\n  geom_line(size = 1) +\n  facet_grid(Sector ~ ., scales = \"free_y\") +  # Arrange facets in rows\n  labs(\n    title = \"Stock Closing Prices Faceted by Sector\",\n    x = \"Date\",\n    y = \"Closing Price (USD)\",\n    color = \"Stock\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\"\n  )\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nCode\n# Display the plot\nprint(p)\n\n\n\n\n\n\n\n\n\nCode\nprint(banking_files)\n\n\n[1] \"./Datasets/Banking/BAC Historical Data.csv\"\n[2] \"./Datasets/Banking/GS Historical Data.csv\" \n[3] \"./Datasets/Banking/JPM Historical Data.csv\"\n[4] \"./Datasets/Banking/MS Historical Data.csv\" \n[5] \"./Datasets/Banking/WFC Historical Data.csv\"",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#opening-price",
    "href": "results.html#opening-price",
    "title": "3  Results",
    "section": "4.3 Opening Price",
    "text": "4.3 Opening Price\n\n\nCode\np &lt;- ggplot(combined_data, aes(x = date, y = open, color = Stock)) +\n  geom_line(size = 1) +\n  facet_grid(Sector ~ ., scales = \"free_y\") +  # Arrange facets in rows\n  labs(\n    title = \"Stock Opening Prices Faceted by Sector\",\n    x = \"Date\",\n    y = \"Closing Price (USD)\",\n    color = \"Stock\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\"\n  )\n\n# Display the plot\nprint(p)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#trade-volume",
    "href": "results.html#trade-volume",
    "title": "3  Results",
    "section": "4.4 Trade Volume",
    "text": "4.4 Trade Volume\n\n\nCode\np &lt;- ggplot(combined_data, aes(x = date, y = volume, color = Stock)) +\n  geom_line(size = 1) +\n  facet_grid(Sector ~ ., scales = \"free_y\") +  # Facet rows by Sector\n  labs(\n    title = \"Stock Trading Volume Faceted by Sector\",\n    x = \"Date\",\n    y = \"Volume\",\n    color = \"Stock\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\"\n  )\n\n# Display the plot\nprint(p)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#stock-analysis-by-events",
    "href": "results.html#stock-analysis-by-events",
    "title": "3  Results",
    "section": "4.5 2. Stock Analysis By Events",
    "text": "4.5 2. Stock Analysis By Events\n\n4.5.1 2.1 Healthcare\n\n\nCode\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(plotly)\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\nCode\nlibrary(zoo)\n\n# Extract stock names from the Source column and pivot the data\nwide_data &lt;- health_data |&gt; \n  mutate(Stock = sub(\" Historical data\", \"\", Source)) |&gt; \n  select(date, close, Stock) |&gt; \n  pivot_wider(names_from = Stock, values_from = close) |&gt; \n  arrange(date)\n\n# Fill missing values using linear interpolation\nwide_data &lt;- wide_data |&gt; \n  mutate(across(-date, ~ na.approx(.x, na.rm = FALSE)))\n\n# Define significant world events and their dates\nevents &lt;- data.frame(\n  date = as.Date(c(\"2019-04-15\", \"2020-03-11\", \"2020-12-14\", \"2021-01-06\", \n                   \"2022-02-24\", \"2023-10-07\", \"2024-11-05\")),\n  event = c(\"Notre-Dame Fire\", \"COVID-19 Declared\", \"Vaccine Rollout Begins\", \n            \"Capitol Riot\", \"Russia Invades Ukraine\", \"Israel-Hamas Conflict\", \n            \"2024 Presidential Election\"),\n  stringsAsFactors = FALSE\n)\n\n# Function to analyze stock performance around event dates\nanalyze_event_impact &lt;- function(stock_data, event_date) {\n  event_date &lt;- as.Date(event_date)\n  pre_event_date &lt;- event_date - days(3)\n  post_event_date &lt;- event_date + days(3)\n  \n  relevant_prices &lt;- stock_data |&gt; \n    filter(date &gt;= pre_event_date & date &lt;= post_event_date)\n  \n  stock_columns &lt;- setdiff(names(relevant_prices), \"date\")\n  \n  returns &lt;- relevant_prices |&gt; \n    mutate(across(all_of(stock_columns), ~ (.x / lag(.x) - 1) * 100, .names = \"{.col}_return\")) |&gt;\n    # Add event date for reference\n    mutate(event_date = event_date)\n  \n  return(returns)\n}\n\n# Apply the function to each event and combine the results\nimpact_results &lt;- events |&gt; \n  rowwise() |&gt; \n  do(analyze_event_impact(wide_data, .$date)) |&gt; \n  ungroup()\n\n# Combine results into a single data frame for reporting\nresults_df &lt;- bind_rows(impact_results)\n\n# Remove rows with all NA values in return columns\nresults_df &lt;- results_df |&gt; \n  filter(if_any(ends_with(\"_return\"), ~ !is.na(.)))\n\n# Prepare data for plotting\nplot_data &lt;- results_df |&gt; \n  pivot_longer(\n    cols = ends_with(\"_return\"), \n    names_to = \"Stock\", \n    values_to = \"Return\",\n    names_pattern = \"(.+)_return\"\n  ) |&gt; \n  filter(!is.na(Return))\n\n# Create interactive plot using plotly\nplot &lt;- plot_ly()\n\n# Add a trace for each stock\nstocks &lt;- unique(plot_data$Stock) # Get unique stock names from plot_data\nfor (stock in stocks) {\n  stock_data &lt;- plot_data |&gt; filter(Stock == stock)\n  \n  plot &lt;- plot |&gt; add_trace(\n    type = 'scatter',\n    mode = 'lines+markers',\n    x = stock_data$date,\n    y = stock_data$Return,\n    name = stock,\n    legendgroup = stock,\n    visible = 'legendonly' # Start with traces hidden\n  )\n}\n\nprint(stocks)\n\n\n[1] \"AZN Historical Data\" \"JNJ\"                 \"LLY Historical Data\"\n[4] \"MRK Historical Data\" \"PFE Historical Data\"\n\n\nCode\n# Add vertical lines for events\nfor (i in seq_along(events$date)) {\n  plot &lt;- plot |&gt; add_segments(\n    x = events$date[i], xend = events$date[i],\n    y = min(plot_data$Return, na.rm = TRUE), yend = max(plot_data$Return, na.rm = TRUE),\n    line = list(color = 'red', dash='dash'),\n    showlegend = FALSE\n  )\n}\n\n# Customize layout\nplot &lt;- plot |&gt; layout(\n  title = \"Stock Price Changes Around Major Events\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Percentage Change (%)\"),\n  hovermode = \"x unified\"\n)\n\n# Display the plot\nplot\n\n\n\n\n\n\n\n\n4.5.2 2.2 Finance\n\n\nCode\nwide_data &lt;- banking_data |&gt; \n  mutate(Stock = sub(\" Historical data\", \"\", Source)) |&gt; \n  select(date, close, Stock) |&gt; \n  pivot_wider(names_from = Stock, values_from = close) |&gt; \n  arrange(date)\n\n# Fill missing values using linear interpolation\nwide_data &lt;- wide_data |&gt; \n  mutate(across(-date, ~ na.approx(.x, na.rm = FALSE)))\n\n# Apply the function to each event and combine the results\nimpact_results &lt;- events |&gt; \n  rowwise() |&gt; \n  do(analyze_event_impact(wide_data, .$date)) |&gt; \n  ungroup()\n\n# Combine results into a single data frame for reporting\nresults_df &lt;- bind_rows(impact_results)\n\n# Remove rows with all NA values in return columns\nresults_df &lt;- results_df |&gt; \n  filter(if_any(ends_with(\"_return\"), ~ !is.na(.)))\n\n# Prepare data for plotting\nplot_data &lt;- results_df |&gt; \n  pivot_longer(\n    cols = ends_with(\"_return\"), \n    names_to = \"Stock\", \n    values_to = \"Return\",\n    names_pattern = \"(.+)_return\"\n  ) |&gt; \n  filter(!is.na(Return))\n\n# Create interactive plot using plotly\nplot &lt;- plot_ly()\n\n# Add a trace for each stock\nstocks &lt;- unique(plot_data$Stock) # Get unique stock names from plot_data\nfor (stock in stocks) {\n  stock_data &lt;- plot_data |&gt; filter(Stock == stock)\n  \n  plot &lt;- plot |&gt; add_trace(\n    type = 'scatter',\n    mode = 'lines+markers',\n    x = stock_data$date,\n    y = stock_data$Return,\n    name = stock,\n    legendgroup = stock,\n    visible = 'legendonly' # Start with traces hidden\n  )\n}\n\n# Add vertical lines for events\nfor (i in seq_along(events$date)) {\n  plot &lt;- plot |&gt; add_segments(\n    x = events$date[i], xend = events$date[i],\n    y = min(plot_data$Return, na.rm = TRUE), yend = max(plot_data$Return, na.rm = TRUE),\n    line = list(color = 'red', dash='dash'),\n    showlegend = FALSE\n  )\n}\n\n# Customize layout\nplot &lt;- plot |&gt; layout(\n  title = \"Stock Price Changes Around Major Events\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Percentage Change (%)\"),\n  hovermode = \"x unified\"\n)\n\n# Display the plot\nplot\n\n\n\n\n\n\n\n\n4.5.3 2.3 Technology\n\n\nCode\n# Extract stock names from the Source column and pivot the data\nwide_data &lt;- tech_data |&gt; \n  mutate(Stock = sub(\" Historical data\", \"\", Source)) |&gt; \n  select(date, close, Stock) |&gt; \n  pivot_wider(names_from = Stock, values_from = close) |&gt; \n  arrange(date)\n\n# Fill missing values using linear interpolation\nwide_data &lt;- wide_data |&gt; \n  mutate(across(-date, ~ na.approx(.x, na.rm = FALSE)))\n\n# Apply the function to each event and combine the results\nimpact_results &lt;- events |&gt; \n  rowwise() |&gt; \n  do(analyze_event_impact(wide_data, .$date)) |&gt; \n  ungroup()\n\n# Combine results into a single data frame for reporting\nresults_df &lt;- bind_rows(impact_results)\n\n# Remove rows with all NA values in return columns\nresults_df &lt;- results_df |&gt; \n  filter(if_any(ends_with(\"_return\"), ~ !is.na(.)))\n\n# Prepare data for plotting\nplot_data &lt;- results_df |&gt; \n  pivot_longer(\n    cols = ends_with(\"_return\"), \n    names_to = \"Stock\", \n    values_to = \"Return\",\n    names_pattern = \"(.+)_return\"\n  ) |&gt; \n  filter(!is.na(Return))\n\n# Create interactive plot using plotly\nplot &lt;- plot_ly()\n\n# Add a trace for each stock\nstocks &lt;- unique(plot_data$Stock) # Get unique stock names from plot_data\nfor (stock in stocks) {\n  stock_data &lt;- plot_data |&gt; filter(Stock == stock)\n  \n  plot &lt;- plot |&gt; add_trace(\n    type = 'scatter',\n    mode = 'lines+markers',\n    x = stock_data$date,\n    y = stock_data$Return,\n    name = stock,\n    legendgroup = stock,\n    visible = 'legendonly' # Start with traces hidden\n  )\n}\n\n# Add vertical lines for events\nfor (i in seq_along(events$date)) {\n  plot &lt;- plot |&gt; add_segments(\n    x = events$date[i], xend = events$date[i],\n    y = min(plot_data$Return, na.rm = TRUE), yend = max(plot_data$Return, na.rm = TRUE),\n    line = list(color = 'red', dash='dash'),\n    showlegend = FALSE\n  )\n}\n\n# Customize layout\nplot &lt;- plot |&gt; layout(\n  title = \"Stock Price Changes Around Major Events\",\n  xaxis = list(title = \"Date\"),\n  yaxis = list(title = \"Percentage Change (%)\"),\n  hovermode = \"x unified\"\n)\n\n# Display the plot\nplot\n\n\n\n\n\n\n\n\n4.5.4 3 Volatility Analysis\n\n\n4.5.5 3.1 Healthcare\n\n\nCode\n# Install and load required packages\n# Install and load required packages\n#install.packages(\"slider\")\nlibrary(slider)\n\n\nWarning: package 'slider' was built under R version 4.4.2\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Calculate daily returns\nhealth_data &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  arrange(date) |&gt;\n  mutate(daily_return = (close / lag(close) - 1) * 100) |&gt;\n  ungroup()\n\n# Calculate volatility (20-day rolling standard deviation of returns)\nhealth_data &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  mutate(volatility = slide_dbl(daily_return, sd, .before = 19, .complete = TRUE)) |&gt;\n  ungroup()\n\n# Calculate average returns\navg_returns &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  summarize(avg_daily_return = mean(daily_return, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_daily_return))\n\nprint(avg_returns)\n\n\n# A tibble: 5 × 2\n  Source              avg_daily_return\n  &lt;chr&gt;                          &lt;dbl&gt;\n1 LLY Historical Data           0.170 \n2 AZN Historical Data           0.0373\n3 MRK Historical Data           0.0243\n4 JNJ Historical data           0.0171\n5 PFE Historical Data          -0.0148\n\n\nCode\nhealth_data_clean &lt;- health_data |&gt; filter(!is.na(daily_return))\n\n# Plot daily returns\nggplot(health_data_clean, aes(x = date, y = daily_return, color = Source)) +\n  geom_line() +\n  labs(title = \"Daily Returns by Stock\", x = \"Date\", y = \"Daily Return (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot volatility\nhealth_data_clean &lt;- health_data |&gt; filter(!is.na(volatility))\nggplot(health_data_clean, aes(x = date, y = volatility, color = Source)) +\n  geom_line() +\n  labs(title = \"Volatility (20-Day Rolling Standard Deviation) by Stock\", x = \"Date\", y = \"Volatility (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(TTR)\n\n\nWarning: package 'TTR' was built under R version 4.4.2\n\n\nCode\nhealth_data &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  mutate(RSI = TTR::RSI(close, n = 14)) |&gt;\n  ungroup()\n\nhealth_data &lt;- health_data |&gt; filter(!is.na(RSI))\n\ncreate_rsi_plot &lt;- function(data, stock_name) {\n  stock_data &lt;- data |&gt; filter(Source == stock_name)\n  \n  ggplot(stock_data, aes(x = date)) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 70, ymax = 100), \n              fill = \"pink\", alpha = 0.2) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 0, ymax = 30), \n              fill = \"lightgreen\", alpha = 0.2) +\n    geom_line(aes(y = RSI), color = \"black\", linewidth = 0.8) +\n    geom_hline(yintercept = 70, color = \"red\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 30, color = \"green\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 50, color = \"gray\", linetype = \"dotted\") +\n    labs(title = paste(\"RSI Over Time -\", stock_name), \n         subtitle = \"With Overbought (&gt;70) and Oversold (&lt;30) Zones\",\n         x = \"Date\", \n         y = \"RSI\") +\n    scale_y_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(\n      panel.grid.minor = element_blank(),\n      axis.text.x = element_text(angle = 45, hjust = 1),\n      plot.title = element_text(face = \"bold\"),\n      plot.subtitle = element_text(size = 9)\n    )\n}\n\n# Create plots for each stock\nstock_names &lt;- unique(health_data$Source)\nfor(stock in stock_names) {\n  print(create_rsi_plot(health_data, stock))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(gridExtra)\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nCode\nlibrary(grid)\nperformance_metrics &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  summarize(\n    sharpe_ratio = mean(daily_return, na.rm = TRUE) / \n                  sd(daily_return, na.rm = TRUE) * sqrt(252),\n    max_drawdown = min(cumsum(daily_return), na.rm = TRUE),\n    avg_volatility = mean(volatility, na.rm = TRUE)\n  ) |&gt;\n  arrange(desc(sharpe_ratio))\n\nprint(performance_metrics)\n\n\n# A tibble: 5 × 4\n  Source              sharpe_ratio max_drawdown avg_volatility\n  &lt;chr&gt;                      &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n1 LLY Historical Data        1.30         0.108           1.86\n2 AZN Historical Data        0.344      -21.5             1.54\n3 MRK Historical Data        0.225      -27.3             1.34\n4 JNJ Historical data        0.190      -20.7             1.08\n5 PFE Historical Data       -0.165      -27.5             1.59\n\n\nCode\n# Calculate rolling metrics\nhealth_data &lt;- health_data |&gt;\n  group_by(Source) |&gt;\n  arrange(date) |&gt;\n  mutate(\n    # Rolling Sharpe Ratio (252-day window)\n    rolling_returns_mean = zoo::rollmean(daily_return, k = 252, fill = NA),\n    rolling_returns_sd = zoo::rollapply(daily_return, width = 252, FUN = sd, fill = NA),\n    rolling_sharpe = (rolling_returns_mean / rolling_returns_sd) * sqrt(252),\n    \n    # Rolling Maximum Drawdown\n    cumulative_return = cumprod(1 + daily_return),\n    rolling_max = zoo::rollmax(cumulative_return, k = 252, fill = NA),\n    rolling_drawdown = (cumulative_return - rolling_max) / rolling_max\n  ) |&gt;\n  ungroup()\n\nhealth_data &lt;- health_data |&gt; filter(!is.na(rolling_sharpe))\nhealth_data &lt;- health_data |&gt; filter(!is.na(rolling_drawdown))\n\n\n# Create rolling Sharpe ratio plot\nsharpe_plot &lt;- ggplot(health_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time (252-day window)\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n# Arrange plots vertically\nggplot(health_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create rolling maximum drawdown plot\ndrawdown_plot &lt;- ggplot(health_data, aes(x = date, y = rolling_drawdown, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time (252-day window)\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nggplot(health_data, aes(x = date, y = rolling_drawdown)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  ) +\n  facet_wrap(~ Source)\n\n\n\n\n\n\n\n\n\n\n\n4.5.6 3.2 Finance\n\n\nCode\n# Install and load required packages\n# Install and load required packages\n#install.packages(\"slider\")\nlibrary(slider)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Calculate daily returns\nbanking_data &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  arrange(date) |&gt;\n  mutate(daily_return = (close / lag(close) - 1) * 100) |&gt;\n  ungroup()\n\n# Calculate volatility (20-day rolling standard deviation of returns)\nbanking_data &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  mutate(volatility = slide_dbl(daily_return, sd, .before = 19, .complete = TRUE)) |&gt;\n  ungroup()\n\n# Calculate average returns\navg_returns &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  summarize(avg_daily_return = mean(daily_return, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_daily_return))\n\nprint(avg_returns)\n\n\n# A tibble: 5 × 2\n  Source              avg_daily_return\n  &lt;chr&gt;                          &lt;dbl&gt;\n1 MS Historical Data            0.103 \n2 GS Historical Data            0.0998\n3 JPM Historical Data           0.0701\n4 WFC Historical Data           0.0557\n5 BAC Historical Data           0.0525\n\n\nCode\nbanking_data_clean &lt;- banking_data |&gt; filter(!is.na(daily_return))\n\n# Plot daily returns\nggplot(banking_data_clean, aes(x = date, y = daily_return, color = Source)) +\n  geom_line() +\n  labs(title = \"Daily Returns by Stock\", x = \"Date\", y = \"Daily Return (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot volatility\nbanking_data_clean &lt;- banking_data |&gt; filter(!is.na(volatility))\nggplot(banking_data_clean, aes(x = date, y = volatility, color = Source)) +\n  geom_line() +\n  labs(title = \"Volatility (20-Day Rolling Standard Deviation) by Stock\", x = \"Date\", y = \"Volatility (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(TTR)\n\nbanking_data &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  mutate(RSI = TTR::RSI(close, n = 14)) |&gt;\n  ungroup()\n\nbanking_data &lt;- banking_data |&gt; filter(!is.na(RSI))\n\ncreate_rsi_plot &lt;- function(data, stock_name) {\n  stock_data &lt;- data |&gt; filter(Source == stock_name)\n  \n  ggplot(stock_data, aes(x = date)) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 70, ymax = 100), \n              fill = \"pink\", alpha = 0.2) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 0, ymax = 30), \n              fill = \"lightgreen\", alpha = 0.2) +\n    geom_line(aes(y = RSI), color = \"black\", linewidth = 0.8) +\n    geom_hline(yintercept = 70, color = \"red\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 30, color = \"green\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 50, color = \"gray\", linetype = \"dotted\") +\n    labs(title = paste(\"RSI Over Time -\", stock_name), \n         subtitle = \"With Overbought (&gt;70) and Oversold (&lt;30) Zones\",\n         x = \"Date\", \n         y = \"RSI\") +\n    scale_y_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(\n      panel.grid.minor = element_blank(),\n      axis.text.x = element_text(angle = 45, hjust = 1),\n      plot.title = element_text(face = \"bold\"),\n      plot.subtitle = element_text(size = 9)\n    )\n}\n\n# Create plots for each stock\nstock_names &lt;- unique(banking_data$Source)\nfor(stock in stock_names) {\n  print(create_rsi_plot(banking_data, stock))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(gridExtra)\nlibrary(grid)\nperformance_metrics &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  summarize(\n    sharpe_ratio = mean(daily_return, na.rm = TRUE) / \n                  sd(daily_return, na.rm = TRUE) * sqrt(252),\n    max_drawdown = min(cumsum(daily_return), na.rm = TRUE),\n    avg_volatility = mean(volatility, na.rm = TRUE)\n  ) |&gt;\n  arrange(desc(sharpe_ratio))\n\nprint(performance_metrics)\n\n\n# A tibble: 5 × 4\n  Source              sharpe_ratio max_drawdown avg_volatility\n  &lt;chr&gt;                      &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n1 GS Historical Data         0.753        -43.4           1.82\n2 MS Historical Data         0.730        -50.4           1.94\n3 JPM Historical Data        0.524        -46.7           1.73\n4 BAC Historical Data        0.358        -54.7           1.95\n5 WFC Historical Data        0.358        -77.2           2.17\n\n\nCode\n# Calculate rolling metrics\nbanking_data &lt;- banking_data |&gt;\n  group_by(Source) |&gt;\n  arrange(date) |&gt;\n  mutate(\n    # Rolling Sharpe Ratio (252-day window)\n    rolling_returns_mean = zoo::rollmean(daily_return, k = 252, fill = NA),\n    rolling_returns_sd = zoo::rollapply(daily_return, width = 252, FUN = sd, fill = NA),\n    rolling_sharpe = (rolling_returns_mean / rolling_returns_sd) * sqrt(252),\n    \n    # Rolling Maximum Drawdown\n    cumulative_return = cumprod(1 + daily_return),\n    rolling_max = zoo::rollmax(cumulative_return, k = 252, fill = NA),\n    rolling_drawdown = (cumulative_return - rolling_max) / rolling_max\n  ) |&gt;\n  ungroup()\n\nbanking_data &lt;- banking_data |&gt; filter(!is.na(rolling_sharpe))\nbanking_data &lt;- banking_data |&gt; filter(!is.na(rolling_drawdown))\n\n\n# Create rolling Sharpe ratio plot\nsharpe_plot &lt;- ggplot(banking_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time (252-day window)\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n# Arrange plots vertically\nggplot(banking_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create rolling maximum drawdown plot\ndrawdown_plot &lt;- ggplot(banking_data, aes(x = date, y = rolling_drawdown, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time (252-day window)\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nggplot(banking_data, aes(x = date, y = rolling_drawdown)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  ) +\n  facet_wrap(~ Source)\n\n\n\n\n\n\n\n\n\n\n\n4.5.7 3.3 Technology\n\n\nCode\nlibrary(slider)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Calculate daily returns\ntech_data &lt;- tech_data %&gt;%\n  group_by(Source) %&gt;%\n  arrange(date) %&gt;%\n  mutate(daily_returns = (close / lag(close) - 1) * 100) %&gt;%\n  ungroup()\n\n# Calculate volatility (20-day rolling standard deviation of returns)\ntech_data &lt;- tech_data %&gt;%\n  group_by(Source) %&gt;%\n  mutate(volatility = slide_dbl(daily_returns, sd, .before = 19, .complete = TRUE)) %&gt;%\n  ungroup()\n\n# Calculate average returns\navg_returns &lt;- tech_data %&gt;%\n  group_by(Source) %&gt;%\n  summarize(avg_daily_return = mean(daily_returns, na.rm = TRUE)) %&gt;%\n  arrange(desc(avg_daily_return))\n\nprint(avg_returns)\n\n\n# A tibble: 5 × 2\n  Source                       avg_daily_return\n  &lt;chr&gt;                                   &lt;dbl&gt;\n1 NVDA historical data                    0.321\n2 MSFT Historical Data                    0.124\n3 META CLASS A Historical data            0.122\n4 AAPL Historical data                    0.119\n5 GOOG class C Historical data            0.100\n\n\nCode\ntech_data_clean &lt;- tech_data %&gt;% filter(!is.na(daily_returns))\n\n# Plot daily returns\nggplot(tech_data_clean, aes(x = date, y = daily_returns, color = Source)) +\n  geom_line() +\n  labs(title = \"Daily Returns by Stock\", x = \"Date\", y = \"Daily Return (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Plot volatility\ntech_data_clean &lt;- tech_data %&gt;% filter(!is.na(volatility))\nggplot(tech_data_clean, aes(x = date, y = volatility, color = Source)) +\n  geom_line() +\n  labs(title = \"Volatility (20-Day Rolling Standard Deviation) by Stock\", x = \"Date\", y = \"Volatility (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(TTR)\n\ntech_data &lt;- tech_data |&gt;\n  group_by(Source) |&gt;\n  mutate(RSI = TTR::RSI(close, n = 14)) |&gt;\n  ungroup()\n\ntech_data &lt;- tech_data %&gt;% filter(!is.na(RSI))\n\ncreate_rsi_plot &lt;- function(data, stock_name) {\n  stock_data &lt;- data %&gt;% filter(Source == stock_name)\n  \n  ggplot(stock_data, aes(x = date)) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 70, ymax = 100), \n              fill = \"pink\", alpha = 0.2) +\n    geom_rect(aes(xmin = min(date), xmax = max(date), ymin = 0, ymax = 30), \n              fill = \"lightgreen\", alpha = 0.2) +\n    geom_line(aes(y = RSI), color = \"black\", linewidth = 0.8) +\n    geom_hline(yintercept = 70, color = \"red\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 30, color = \"green\", linetype = \"dashed\", linewidth = 0.8) +\n    geom_hline(yintercept = 50, color = \"gray\", linetype = \"dotted\") +\n    labs(title = paste(\"RSI Over Time -\", stock_name), \n         subtitle = \"With Overbought (&gt;70) and Oversold (&lt;30) Zones\",\n         x = \"Date\", \n         y = \"RSI\") +\n    scale_y_continuous(limits = c(0, 100)) +\n    theme_minimal() +\n    theme(\n      panel.grid.minor = element_blank(),\n      axis.text.x = element_text(angle = 45, hjust = 1),\n      plot.title = element_text(face = \"bold\"),\n      plot.subtitle = element_text(size = 9)\n    )\n}\n\n# Create plots for each stock\nstock_names &lt;- unique(tech_data$Source)\nfor(stock in stock_names) {\n  print(create_rsi_plot(tech_data, stock))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(gridExtra)\nlibrary(grid)\nperformance_metrics &lt;- tech_data %&gt;%\n  group_by(Source) %&gt;%\n  summarize(\n    sharpe_ratio = mean(daily_returns, na.rm = TRUE) / \n                  sd(daily_returns, na.rm = TRUE) * sqrt(252),\n    max_drawdown = min(cumsum(daily_returns), na.rm = TRUE),\n    avg_volatility = mean(volatility, na.rm = TRUE)\n  ) %&gt;%\n  arrange(desc(sharpe_ratio))\n\nprint(performance_metrics)\n\n\n# A tibble: 5 × 4\n  Source                       sharpe_ratio max_drawdown avg_volatility\n  &lt;chr&gt;                               &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;\n1 NVDA historical data                1.51         -2.03           3.18\n2 AAPL Historical data                0.940       -13.3            1.81\n3 GOOG class C Historical data        0.771       -21.1            1.89\n4 MSFT Historical Data                0.694       -46.7            2.55\n5 META CLASS A Historical data        0.684       -46.8            2.55\n\n\nCode\n# Calculate rolling metrics\ntech_data &lt;- tech_data %&gt;%\n  group_by(Source) %&gt;%\n  arrange(date) %&gt;%\n  mutate(\n    # Rolling Sharpe Ratio (252-day window)\n    rolling_returns_mean = zoo::rollmean(daily_returns, k = 252, fill = NA),\n    rolling_returns_sd = zoo::rollapply(daily_returns, width = 252, FUN = sd, fill = NA),\n    rolling_sharpe = (rolling_returns_mean / rolling_returns_sd) * sqrt(252),\n    \n    # Rolling Maximum Drawdown\n    cumulative_return = cumprod(1 + daily_returns),\n    rolling_max = zoo::rollmax(cumulative_return, k = 252, fill = NA),\n    rolling_drawdown = (cumulative_return - rolling_max) / rolling_max\n  ) %&gt;%\n  ungroup()\n\ntech_data &lt;- tech_data %&gt;% filter(!is.na(rolling_sharpe))\ntech_data &lt;- tech_data %&gt;% filter(!is.na(rolling_drawdown))\n\n\n# Create rolling Sharpe ratio plot\nsharpe_plot &lt;- ggplot(tech_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time (252-day window)\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n# Arrange plots vertically\nggplot(tech_data, aes(x = date, y = rolling_sharpe, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Sharpe Ratio Over Time\",\n       x = \"Date\", y = \"Sharpe Ratio\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create rolling maximum drawdown plot\ndrawdown_plot &lt;- ggplot(tech_data, aes(x = date, y = rolling_drawdown, color = Source)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time (252-day window)\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nggplot(tech_data, aes(x = date, y = rolling_drawdown)) +\n  geom_line() +\n  labs(title = \"Rolling Maximum Drawdown Over Time\",\n       x = \"Date\", y = \"Drawdown\") +\n  theme_minimal() +\n  theme(\n    panel.grid.minor = element_blank(),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  ) +\n  facet_wrap(~ Source)\n\n\n\n\n\n\n\n\n\n\n\n4.5.8 4 Seasonal Patterns and Cycles\n\n4.5.8.1 4.1. Healthcare\n\n\nCode\nlibrary(purrr)\n# Clean and prepare the data\nhealth_data &lt;- health_data %&gt;%\n  filter(!is.na(date) & !is.na(close)) %&gt;%  # Remove rows with missing Date or Price\n  mutate(Date = as.Date(date)) %&gt;%          # Convert Date to Date format\n  arrange(Sector, Source, date)\n\n# Define a function to perform seasonal decomposition and Fourier analysis\nanalyze_seasonal_patterns &lt;- function(data, sector) {\n  # Filter data for the given sector\n  sector_data &lt;- data %&gt;% filter(Sector == sector)\n\n  # Perform analysis for each stock\n  sector_analysis &lt;- sector_data %&gt;%\n    group_by(Source) %&gt;%\n    summarise(\n      decomposed_plot = list({\n        tryCatch({\n          # Convert to time series object\n          ts_data &lt;- ts(\n            close,\n            frequency = 365,\n            start = c(year(min(date)), yday(min(date)))\n          )\n\n          # Seasonal decomposition\n          decomposed &lt;- stl(ts_data, s.window = \"periodic\")\n\n          # Plot decomposition\n          autoplot(decomposed) + \n            ggtitle(paste(\"Seasonal Decomposition of\", sector, \"-\", unique(Source)))\n        }, error = function(e) {\n          message(paste(\"Error processing decomposition for stock:\", unique(Source)))\n          NULL\n        })\n      }),\n      fourier_plot = list({\n        tryCatch({\n          # Fourier transform\n          ts_data &lt;- ts(\n            close,\n            frequency = 365,\n            start = c(year(min(date)), yday(min(date)))\n          )\n          spec &lt;- spectrum(ts_data, spans = c(3, 3))\n\n          # Return spectral density plot\n          ggplot(data.frame(Frequency = spec$freq, SpectralDensity = spec$spec),\n                 aes(x = Frequency, y = SpectralDensity)) +\n            geom_line() +\n            ggtitle(paste(\"Spectral Density of\", sector, \"-\", unique(Source)))\n        }, error = function(e) {\n          message(paste(\"Error processing Fourier analysis for stock:\", unique(Source)))\n          NULL\n        })\n      })\n    )\n\n  # Return analysis\n  return(sector_analysis)\n}\n\n# Perform analysis sector by sector\nsectors &lt;- unique(health_data$Sector)\nresults &lt;- map(sectors, ~ analyze_seasonal_patterns(health_data, .x))\n\n\nError processing decomposition for stock: AZN Historical Data\n\n\nError processing decomposition for stock: JNJ Historical data\n\n\nError processing decomposition for stock: LLY Historical Data\n\n\nError processing decomposition for stock: MRK Historical Data\n\n\nError processing decomposition for stock: PFE Historical Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save or display plots\nwalk2(sectors, results, function(sector, sector_result) {\n  message(paste(\"Processing sector:\", sector))\n  walk2(sector_result$decomposed_plot, sector_result$fourier_plot, function(decomp_plot, fourier_plot) {\n    if (!is.null(decomp_plot)) print(decomp_plot)\n    if (!is.null(fourier_plot)) print(fourier_plot)\n  })\n})\n\n\nProcessing sector: Healthcare\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.8.2 4.2 Finance\n\n\nCode\n# Clean and prepare the data\nbanking_data &lt;- banking_data %&gt;%\n  filter(!is.na(date) & !is.na(close)) %&gt;%  # Remove rows with missing Date or Price\n  mutate(Date = as.Date(date)) %&gt;%          # Convert Date to Date format\n  arrange(Sector, Source, date)\n\n# Perform analysis sector by sector\nsectors &lt;- unique(banking_data$Sector)\nresults &lt;- map(sectors, ~ analyze_seasonal_patterns(banking_data, .x))\n\n\nError processing decomposition for stock: BAC Historical Data\n\n\nError processing decomposition for stock: GS Historical Data\n\n\nError processing decomposition for stock: JPM Historical Data\n\n\nError processing decomposition for stock: MS Historical Data\n\n\nError processing decomposition for stock: WFC Historical Data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save or display plots\nwalk2(sectors, results, function(sector, sector_result) {\n  message(paste(\"Processing sector:\", sector))\n  walk2(sector_result$decomposed_plot, sector_result$fourier_plot, function(decomp_plot, fourier_plot) {\n    if (!is.null(decomp_plot)) print(decomp_plot)\n    if (!is.null(fourier_plot)) print(fourier_plot)\n  })\n})\n\n\nProcessing sector: Banking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.8.3 4.3 Technology\n\n\nCode\n# Load necessary libraries\nlibrary(tidyverse)\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ tibble  3.2.1\n✔ stringr 1.5.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ gridExtra::combine() masks dplyr::combine()\n✖ plotly::filter()     masks dplyr::filter(), stats::filter()\n✖ dplyr::lag()         masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nCode\nlibrary(lubridate)\nlibrary(forecast)\n\n\nWarning: package 'forecast' was built under R version 4.4.2\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nCode\nlibrary(ggplot2)\nlibrary(tseries)\n\n\nWarning: package 'tseries' was built under R version 4.4.2\n\n\nCode\n# Clean and prepare the data\ntech_data &lt;- tech_data %&gt;%\n  filter(!is.na(date) & !is.na(close)) %&gt;%  # Remove rows with missing Date or Price\n  mutate(Date = as.Date(date)) %&gt;%          # Convert Date to Date format\n  arrange(Sector, Source, date)\n\n\n# Perform analysis sector by sector\nsectors &lt;- unique(tech_data$Sector)\nresults &lt;- map(sectors, ~ analyze_seasonal_patterns(tech_data, .x))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Save or display plots\nwalk2(sectors, results, function(sector, sector_result) {\n  message(paste(\"Processing sector:\", sector))\n  walk2(sector_result$decomposed_plot, sector_result$fourier_plot, function(decomp_plot, fourier_plot) {\n    if (!is.null(decomp_plot)) print(decomp_plot)\n    if (!is.null(fourier_plot)) print(fourier_plot)\n  })\n})\n\n\nProcessing sector: Technology\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nunique_finance_sources &lt;- unique(banking_data$Source)\nunique_healthcare_sources &lt;- unique(health_data$Source)\nunique_tech_sources &lt;- unique(tech_data$Source)\n\nmodify_file_path &lt;- function(file_path) {\n  file_name &lt;- tools::file_path_sans_ext(file_path)  \n  file_extension &lt;- tools::file_ext(file_path)      #\n  modified_file_path &lt;- paste0(file_name, \"_modified.\", file_extension)\n  return(modified_file_path)\n}\n\nfor (source in unique_finance_sources) {\n  file_path &lt;- stock_file_mapping[source]\n  bank_data_source &lt;- banking_data |&gt; filter(Source == source)\n  modified_path &lt;- modify_file_path(file_path)\n  save_to_csv(bank_data_source, modified_path)\n}\n\nfor (source in unique_healthcare_sources) {\n  file_path &lt;- stock_file_mapping[source]\n  healthcare_source &lt;- health_data |&gt; filter(Source == source)\n  modified_path &lt;- modify_file_path(file_path)\n  save_to_csv(healthcare_source, modified_path)\n  \n  \n}\n\nfor (source in unique_tech_sources) {\n  file_path &lt;- stock_file_mapping[source]\n  tech_source &lt;- tech_data |&gt; filter(Source == source)\n  modified_path &lt;- modify_file_path(file_path)\n  save_to_csv(healthcare_source, modified_path)\n}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  }
]