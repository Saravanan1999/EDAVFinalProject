[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDAV Project",
    "section": "",
    "text": "1 Introduction\nThis project aims to analyze the performance of stocks in each sector for major corporations by identifying trends and understanding the factors influencing stock price variations across various sectors. Stock prices are determined not only by a company’s performance but also by broader market trends, sector-specific dynamics, and external economic factors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "EDAV Project",
    "section": "1.1 Background",
    "text": "1.1 Background\nFor example, greater stock prices are frequently connected with technology companies because investors anticipate innovation and development from these companies. On the other hand, utility firms tend to have lower stock values due to the nature of their business, primarily dependent on consistent demand and regulated pricing. Understanding these distinctions is critical for investors looking to make educated decisions based on sectoral performance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "EDAV Project",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nThrough this analysis, we aim to explore:\n\nWhy some firms in the same industry outperform others.\nThe impact of factors such as market sentiment, growth prospects, competitive advantages, and financial soundness on stock performance.\nThe influence of external events such as economic downturns, market booms, and geopolitical crises on stock performance across sectors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#methodology",
    "href": "index.html#methodology",
    "title": "EDAV Project",
    "section": "1.3 Methodology",
    "text": "1.3 Methodology\nTo achieve these goals, we will:\n\nUtilize bar charts, scatter plots, and sector performance comparisons to visually highlight key insights.\nAnalyze the relative success of each sector over time.\nInvestigate the underlying causes of performance disparities using data-driven approaches.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#expected-outcomes",
    "href": "index.html#expected-outcomes",
    "title": "EDAV Project",
    "section": "1.4 Expected Outcomes",
    "text": "1.4 Expected Outcomes\nBy the end of the research, we aim to present:\n\nA clear, data-driven narrative about how different sectors perform in the market.\nInsights into the variables influencing their success.\n\nThese visual tools and analyses will enable us to better understand sectoral performance and provide actionable insights for informed investment decisions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nFor this project, we will use historical stock data for companies in three key sectors: Technology, Finance, and Healthcare. The dataset will span five years, allowing for a robust analysis of trends over time.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "2.1.1 Sectors and Companies\n\n2.1.1.1 Technology:\n\nApple Inc. (AAPL)\nAlphabet Inc. Class C (GOOG)\nMeta Platforms Inc. Class A (META)\nMicrosoft Corp. (MSFT)\nNVIDIA Corporation (NVDA)\n\n\n\n2.1.1.2 Finance:\n\nBank of America (BAC)\nGoldman Sachs Group Inc. (GS)\nJPMorgan Chase & Co. (JPM)\nMorgan Stanley (MS)\nWells Fargo & Co. (WFC)\n\n\n\n2.1.1.3 Healthcare:\n\nAstraZeneca (AZN)\nJohnson & Johnson (JNJ)\nEli Lilly and Co. (LLY)\nMerck & Co., Inc. (MRK)\nPfizer Inc. (PFE)\n\n\n\n\n2.1.2 Data Source\nNasdaq collects data through its exchange from transactions conducted by various market participants, including institutional investors, brokers, market makers, and retail traders. The data encompasses details on market activity such as trades, order books, bid/ask prices, volumes, and timestamped events.\n\n2.1.2.1 Transaction Data\nEach trade, quote, and order is logged, providing insights into the dynamics of stock movements, liquidity, and market trends.\n\n\n2.1.2.2 Participants\nMarket participants, including broker-dealers and investors, generate real-time and historical data through their buying and selling activities.\n\n\n\n2.1.3 Format and Frequency\nThe data will be accessed in formats like CSV, JSON, or XML, which are compatible with analysis tools such as Python or R. The frequency of updates varies:\n\nDaily Data: Updated at the end of each trading day.\nIntraday (Minute-Level) Data: Real-time updates available during market hours.\n\n\n\n2.1.4 Key Data Dimensions\n\nDate: Trading date.\n\nOpen: Opening stock price.\n\nHigh: Highest price during the trading day.\n\nLow: Lowest price during the trading day.\n\nClose/Last: Closing price or last trade price.\n\nVolume: Total shares traded.\n\n\n\n2.1.5 Potential Issues\n\nData Gaps: Missing data during market holidays or after-hours trading.\nAdjustments: Stock splits and dividends may require corrections for consistency.\n\nData Volume: Handling minute-level data over five years for multiple companies may require significant processing power and storage.\n\n\n\n2.1.6 Data Import Plan\nThe data import strategy entails retrieving structured information from an API endpoint using HTTP requests that include appropriate headers to ensure successful communication. The JSON answer is processed and turned into a structured DataFrame, allowing for rapid data manipulation and analysis. Relevant data is then extracted and saved locally in a CSV file for further processing and analysis. This methodical methodology guarantees the smooth integration of raw data from an external source into a useful tabular format.\n\n\n2.1.7 Sources\nNasdaq’s market data services will be the primary source, with potential supplementary data from financial APIs or publicly available CSV datasets.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis\n\n\nCode\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(readr)\n\n\nData fetching:\n\n\nCode\nfetch_and_save_data &lt;- function(api_url, csv_path) {\n  response &lt;- GET(api_url, add_headers(\"User-Agent\" = \"Mozilla/5.0\"))\n  \n  if (status_code(response) == 200) {\n    json_content &lt;- content(response, as = \"text\", encoding = \"UTF-8\")\n    parsed_data &lt;- fromJSON(json_content, flatten = TRUE)\n    \n    historical_data &lt;- parsed_data$data$tradesTable$rows\n    \n    data_frame &lt;- as.data.frame(historical_data)\n    \n    write_csv(data_frame, csv_path)\n    \n    print(paste(\"Data successfully saved to\", csv_path))\n  } else {\n    print(paste(\"Failed to fetch data. HTTP Status Code:\", status_code(response)))\n  }\n}\n\n\n###Finance Sector\nFetching data\n\n\nCode\n# bank\nBAC_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/BAC/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=27\"\nBAC_csv_path &lt;- \"./Datasets/Banking/BAC Historical Data.csv\"\nfetch_and_save_data(BAC_history_data_url, BAC_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Banking/BAC Historical Data.csv\"\n\n\nCode\nGS_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/GS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=26\"\nGS_csv_path &lt;- \"./Datasets/Banking/GS Historical Data.csv\"\nfetch_and_save_data(GS_history_data_url, GS_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Banking/GS Historical Data.csv\"\n\n\nCode\nJPM_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/JPM/historical?assetclass=stocks&fromdate=2024-10-20&limit=9999&todate=2024-11-20&random=29\"\nJPM_csv_path &lt;- \"./Datasets/Banking/JPM Historical Data.csv\"\nfetch_and_save_data(JPM_history_data_url, JPM_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Banking/JPM Historical Data.csv\"\n\n\nCode\nMS_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=15\"\nMS_csv_path &lt;- \"./Datasets/Banking/MS Historical Data.csv\"\nfetch_and_save_data(MS_history_data_url, MS_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Banking/MS Historical Data.csv\"\n\n\nCode\nWFC_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MS/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=15\"\nWFC_csv_path &lt;- \"./Datasets/Banking/MS Historical Data.csv\"\nfetch_and_save_data(WFC_history_data_url, WFC_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Banking/MS Historical Data.csv\"\n\n\nReading data:\n\n\nCode\nBAC &lt;- read_csv(BAC_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nGS &lt;- read_csv(GS_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nJPM &lt;- read_csv(JPM_csv_path)\n\n\nRows: 23 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nMS &lt;- read_csv(MS_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\nWFC &lt;- read_csv(WFC_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nChecking Null Values:\n\n\nCode\nmissing_values &lt;- list(\n  \"BAC\" = colSums(is.na(BAC)),\n  \"GS\" = colSums(is.na(GS)),\n  \"JPM\" = colSums(is.na(JPM)),\n  \"MS\" = colSums(is.na(MS)),\n  \"WFC\" = colSums(is.na(WFC))\n)\n\nfor (name in names(missing_values)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(missing_values[[name]])\n  cat(\"\\n\")\n}\n\n\nMissing values in BAC dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in GS dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in JPM dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MS dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in WFC dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nVisualizing Missing Data:\n\n\nCode\nlibrary(ggplot2)\nlibrary(naniar)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(tidyr)\n\n\n\n\nCode\n# List of datasets\ndata_list &lt;- list(BAC = BAC, GS = GS, JPM = JPM, MS = MS, WFC = WFC)\n\n# Generate missing value visualizations\nfor (name in names(data_list)) {\n  cat(\"Visualizing missing data for\", name, \"\\n\")\n  \n  # Plot\n  print(\n    vis_miss(data_list[[name]]) +\n      ggtitle(paste(\"Missing Data Visualization for\", name))\n  )\n}\n\n\nVisualizing missing data for BAC \n\n\n\n\n\n\n\n\n\nVisualizing missing data for GS \n\n\n\n\n\n\n\n\n\nVisualizing missing data for JPM \n\n\n\n\n\n\n\n\n\nVisualizing missing data for MS \n\n\n\n\n\n\n\n\n\nVisualizing missing data for WFC \n\n\n\n\n\n\n\n\n\n\n\nCode\n# List of datasets\ndata_list &lt;- list(BAC = BAC, GS = GS, JPM = JPM, MS = MS, WFC = WFC)\n\n# Combine all datasets into one data frame with a 'Dataset' column indicating the dataset name\ncombined_data &lt;- bind_rows(lapply(names(data_list), function(dataset_name) {\n  data &lt;- data_list[[dataset_name]]\n  data$Dataset &lt;- dataset_name\n  return(data)\n}))\n\n# Convert all columns to character type\ncombined_data &lt;- combined_data %&gt;%\n  mutate(across(everything(), as.character))\n\n# Pivot longer and add a column for missing data\ncombined_data_long &lt;- combined_data %&gt;%\n  pivot_longer(cols = -Dataset, names_to = \"Column\", values_to = \"Value\") %&gt;%\n  mutate(Missing = is.na(Value))\n\n# Plot the missing data across datasets\nggplot(combined_data_long, aes(x = Column, y = Dataset, fill = Missing)) +\n  geom_tile(color = \"white\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"red\", \"FALSE\" = \"gray90\")) +\n  theme_minimal() +\n  ggtitle(\"Missing Data Visualization Across Datasets\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability\n\n\n\n\n\n\n\n\n\nFor the finance sector dataset, we have plotted two types of graphs:\nA missing value heatmap for each company, which shows that there are no missing values across any column for each company. A comparative heatmap of the five companies in the finance sector, which confirms that none of the columns in any of the five datasets have missing values.\n###Tech Sector\nFetching data\n\n\nCode\nAAPL_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/AAPL/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=21\"\nAAPL_csv_path &lt;- \"./Datasets/TECH/AAPL Historical data.csv\"\nfetch_and_save_data(AAPL_history_data_url, AAPL_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/TECH/AAPL Historical data.csv\"\n\n\nCode\nGOOG_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/GOOG/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=32\"\nGOOG_csv_path &lt;- \"./Datasets/TECH/GOOG class C Historical data.csv\"\nfetch_and_save_data(GOOG_history_data_url, GOOG_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/TECH/GOOG class C Historical data.csv\"\n\n\nCode\nMETA_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/META/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=13\"\nMETA_csv_path &lt;- \"./Datasets/TECH/GOOG class C Historical data.csv\"\nfetch_and_save_data(GOOG_history_data_url, GOOG_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/TECH/GOOG class C Historical data.csv\"\n\n\nCode\nMSFT_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/META/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=13\"\nMSFT_csv_path &lt;- \"./Datasets/TECH/MSFT Historical data.csv\"\nfetch_and_save_data(MSFT_history_data_url, MSFT_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/TECH/MSFT Historical data.csv\"\n\n\nCode\nNVDA_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/NVDA/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=49\"\nNVDA_csv_path &lt;- \"./Datasets/TECH/NVDA historical data.csv\"\nfetch_and_save_data(NVDA_history_data_url, NVDA_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/TECH/NVDA historical data.csv\"\n\n\nReading data\n\n\nCode\naapl = read_csv(AAPL_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\ngoog = read_csv(GOOG_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmeta = read_csv(META_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmsft = read_csv(MSFT_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nnvda = read_csv(NVDA_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\n#missing data\ndatasets &lt;- list(\n  \"AAPL\" = aapl,\n  \"GOOG\" = goog,\n  \"META\" = meta,\n  \"MSFT\" = msft,\n  \"NVDA\" = nvda\n)\n\nfor (name in names(datasets)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(colSums(is.na(datasets[[name]])))\n  cat(\"\\n\")\n}\n\n\nMissing values in AAPL dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in GOOG dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in META dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MSFT dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in NVDA dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nCode\n#missing values visualisation\n#install.packages('naniar')\n#install.packages('VIM')\n#library(dplyr)\n#library(tidyverse)\n#library(ggplot2)\n#library(naniar)\n\n# Assuming the files are named file1, file2, ..., file5\naapl$Source &lt;- \"Apple\"\ngoog$Source &lt;- \"Google\"\nmeta$Source &lt;- \"Meta\"\nmsft$Source &lt;- \"Microsoft\"\nnvda$Source &lt;- \"Nvidia\"\n\n# Combine the datasets\nall_files &lt;- bind_rows(aapl, goog, meta, msft, nvda)\n\n# Reshape data for visualization\n# Create a missingness indicator for each column\nall_files &lt;- all_files  |&gt; \n  mutate(across(-Source, as.character))\n\n# Pivot the data\nmissing_long &lt;- all_files  |&gt; \n  pivot_longer(cols = -Source, names_to = \"Variable\", values_to = \"Value\")  |&gt; \n  mutate(Missing = is.na(Value))\nlibrary(ggplot2)\n\nggplot(missing_long, aes(x = Variable, y = Source, fill = Missing)) +\n  geom_tile(color = \"white\") +\n  scale_fill_manual(\n    values = c(\"TRUE\" = \"red\", \"FALSE\" = \"blue\"),\n    labels = c(\"TRUE\" = \"Missing\", \"FALSE\" = \"Not Missing\")\n  ) +\n  theme_minimal() +\n  labs(\n    title = \"Missing Data Across Files\",\n    x = \"Variables\",\n    y = \"Files\",\n    fill = \"Missing?\"\n  ) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\n\nThere are 2 of types visualizations we have done to depict the missing values in the data.One using regular ggplot and the other using the naniar package.As seen from the graphs, there are no missing values.This trend can be attributed to the fact that all stocks have a price and they are updated accordingly. To deal with historical data, NASDAQ would probably use multiple techniques like archival techniques and curation processes etc. Another widely known fact is that financial data is almost always very clean.\n###Healthcare and Pharma Sector\nFetch Data:\n\n\nCode\nJNJ_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/JNJ/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=45\"\nJNJ_csv_path &lt;- \"./Datasets/Healthcare and Pharma/JNJ Historical data.csv\"\nfetch_and_save_data(JNJ_history_data_url, JNJ_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Healthcare and Pharma/JNJ Historical data.csv\"\n\n\nCode\nAZN_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/AZN/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=20\"\nAZN_csv_path &lt;- \"./Datasets/Healthcare and Pharma/AZN Historical data.csv\"\nfetch_and_save_data(AZN_history_data_url, AZN_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Healthcare and Pharma/AZN Historical data.csv\"\n\n\nCode\nLLY_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/LLY/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=22\"\nLLY_csv_path &lt;- \"./Datasets/Healthcare and Pharma/LLY Historical data.csv\"\nfetch_and_save_data(LLY_history_data_url, LLY_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Healthcare and Pharma/LLY Historical data.csv\"\n\n\nCode\nMRK_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/MRK/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=33\"\nMRK_csv_path &lt;- \"./Datasets/Healthcare and Pharma/MRK Historical data.csv\"\nfetch_and_save_data(MRK_history_data_url, MRK_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Healthcare and Pharma/MRK Historical data.csv\"\n\n\nCode\nPFE_history_data_url &lt;- \"https://api.nasdaq.com/api/quote/PFE/historical?assetclass=stocks&fromdate=2019-11-20&limit=9999&todate=2024-11-20&random=49\"\nPFE_csv_path &lt;- \"./Datasets/Healthcare and Pharma/PFE Historical data.csv\"\nfetch_and_save_data(PFE_history_data_url, PFE_csv_path)\n\n\n[1] \"Data successfully saved to ./Datasets/Healthcare and Pharma/PFE Historical data.csv\"\n\n\nReading Data:\n\n\nCode\n# Reading the datasets using relative paths\njnj = read_csv(JNJ_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nazn = read_csv(AZN_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nlly = read_csv(LLY_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\nmrk = read_csv(MRK_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCode\npfe = read_csv(PFE_csv_path)\n\n\nRows: 1259 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): date, close, open, high, low\nnum (1): volume\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nCode\npharma_datasets &lt;- list(\n  \"JNJ\" = jnj,\n  \"AZN\" = azn,\n  \"LLY\" = lly,\n  \"MRK\" = mrk,\n  \"PFE\" = pfe\n)\n\nfor (name in names(pharma_datasets)) {\n  cat(paste(\"Missing values in\", name, \"dataset:\\n\"))\n  print(colSums(is.na(pharma_datasets[[name]])))\n  cat(\"\\n\")\n}\n\n\nMissing values in JNJ dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in AZN dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in LLY dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in MRK dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\nMissing values in PFE dataset:\n  date  close volume   open   high    low \n     0      0      0      0      0      0 \n\n\nMissing Values Visualisation\n\n\nCode\n# Assuming the files are named file1, file2, ..., file5\njnj$Source &lt;- \"JNJ\"\nazn$Source &lt;- \"AstraZeneca\"\nlly$Source &lt;- \"Eli Lilly\"\nmrk$Source &lt;- \"Merck&Co\"\npfe$Source &lt;- \"Pfizer\"\n\n# Combine the datasets\nall_files_health &lt;- bind_rows(jnj, azn, lly, mrk, pfe)\n\n# Reshape data for visualization\n# Create a missingness indicator for each column\nall_files_health &lt;- all_files_health  |&gt; \n  mutate(across(-Source, as.character))\n\n# Pivot the data\nmissing_long &lt;- all_files_health  |&gt; \n  pivot_longer(cols = -Source, names_to = \"Variable\", values_to = \"Value\")  |&gt; \n  mutate(Missing = is.na(Value))\nlibrary(ggplot2)\nlibrary(naniar)\n\ngg_miss_var(all_files_health, facet = Source) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Missing Data Visualization by File\")\n\n\n\n\n\n\n\n\n\nWe have used naniar package to visualise missing data. The x-axis shows the proportion of data missing in the dataset and here since its 0, it means there are no missing values. The reason why has been explained above.\nThere are 3 of types visualizations we have done to depict the missing values in the data. Two using regular ggplot and the other using the naniar package. As seen from the graphs, there are no missing values.This trend can be attributed to the fact that all stocks have a price and they are updated accordingly. To deal with historical data, NASDAQ would probably use multiple techniques like archival techniques and curation processes etc. Another widely known fact is that financial data is almost always very clean.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  }
]